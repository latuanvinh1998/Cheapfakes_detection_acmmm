{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9de6fda9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=16, bidirectional=0, cnn_type='vgg19', crop_size=224, data_name='coco_precomp', data_path='/media/vinh/Not_mix3/Research/ACMMM/', dim_hidden=512, dim_vid=2048, dim_word=300, embed_size=2048, finetune=False, grad_clip=2.0, img_dim=2048, input_dropout_p=0.2, learning_rate=0.0002, log_step=10, logger_name='runs/runX', lr_update=15, margin=0.2, max_len=350, max_violation=False, measure='cosine', no_imgnorm=False, num_epochs=100, num_layers=1, reset_train=False, resume='', rnn_dropout_p=0.5, rnn_type='gru', use_abs=False, use_restval=False, val_step=10000, vocab_path='vocab/', word_dim=300, workers=10)\n"
     ]
    }
   ],
   "source": [
    "from vocab import Vocabulary\n",
    "from model import VSRN\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import sys\n",
    "\n",
    "from transformers import pipeline\n",
    "from transformers import *\n",
    "import WK_Sbert.utils_sbert\n",
    "\n",
    "import numpy as np\n",
    "import argparse\n",
    "import pickle, os\n",
    "import json\n",
    "import nltk\n",
    "import torch\n",
    "import sys\n",
    "import random\n",
    "sys.path.append('../')\n",
    "from utils_ import *\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--data_path', default='/media/vinh/Not_mix3/Research/ACMMM/',\n",
    "                    help='path to datasets')\n",
    "parser.add_argument('--data_name', default='coco_precomp',\n",
    "                    help='{coco,f8k,f30k,10crop}_precomp|coco|f8k|f30k')\n",
    "parser.add_argument('--vocab_path', default='vocab/',\n",
    "                    help='Path to saved vocabulary pickle files.')\n",
    "parser.add_argument('--margin', default=0.2, type=float,\n",
    "                    help='Rank loss margin.')\n",
    "parser.add_argument('--num_epochs', default=100, type=int,\n",
    "                    help='Number of training epochs.')\n",
    "parser.add_argument('--batch_size', default=16, type=int,\n",
    "                    help='Size of a training mini-batch.')\n",
    "parser.add_argument('--word_dim', default=300, type=int,\n",
    "                    help='Dimensionality of the word embedding.')\n",
    "parser.add_argument('--embed_size', default=2048, type=int,\n",
    "                    help='Dimensionality of the joint embedding.')\n",
    "parser.add_argument('--grad_clip', default=2., type=float,\n",
    "                    help='Gradient clipping threshold.')\n",
    "parser.add_argument('--crop_size', default=224, type=int,\n",
    "                    help='Size of an image crop as the CNN input.')\n",
    "parser.add_argument('--num_layers', default=1, type=int,\n",
    "                    help='Number of GRU layers.')\n",
    "parser.add_argument('--learning_rate', default=.0002, type=float,\n",
    "                    help='Initial learning rate.')\n",
    "parser.add_argument('--lr_update', default=15, type=int,\n",
    "                    help='Number of epochs to update the learning rate.')\n",
    "parser.add_argument('--workers', default=10, type=int,\n",
    "                    help='Number of data loader workers.')\n",
    "parser.add_argument('--log_step', default=10, type=int,\n",
    "                    help='Number of steps to print and record the log.')\n",
    "parser.add_argument('--val_step', default=10000, type=int,\n",
    "                    help='Number of steps to run validation.')\n",
    "parser.add_argument('--logger_name', default='runs/runX',\n",
    "                    help='Path to save the model and Tensorboard log.')\n",
    "parser.add_argument('--resume', default='', type=str, metavar='PATH',\n",
    "                    help='path to latest checkpoint (default: none)')\n",
    "parser.add_argument('--max_violation', action='store_true',\n",
    "                    help='Use max instead of sum in the rank loss.')\n",
    "parser.add_argument('--img_dim', default=2048, type=int,\n",
    "                    help='Dimensionality of the image embedding.')\n",
    "parser.add_argument('--finetune', action='store_true',\n",
    "                    help='Fine-tune the image encoder.')\n",
    "parser.add_argument('--cnn_type', default='vgg19',\n",
    "                    help=\"\"\"The CNN used for image encoder\n",
    "                    (e.g. vgg19, resnet152)\"\"\")\n",
    "parser.add_argument('--use_restval', action='store_true',\n",
    "                    help='Use the restval data for training on MSCOCO.')\n",
    "parser.add_argument('--measure', default='cosine',\n",
    "                    help='Similarity measure used (cosine|order)')\n",
    "parser.add_argument('--use_abs', action='store_true',\n",
    "                    help='Take the absolute value of embedding vectors.')\n",
    "parser.add_argument('--no_imgnorm', action='store_true',\n",
    "                    help='Do not normalize the image embeddings.')\n",
    "parser.add_argument('--reset_train', action='store_true',\n",
    "                    help='Ensure the training is always done in '\n",
    "                    'train mode (Not recommended).')\n",
    "\n",
    "###caption parameters\n",
    "parser.add_argument(\n",
    "    '--dim_vid',\n",
    "    type=int,\n",
    "    default=2048,\n",
    "    help='dim of features of video frames')\n",
    "parser.add_argument(\n",
    "    '--dim_hidden',\n",
    "    type=int,\n",
    "    default=512,\n",
    "    help='size of the rnn hidden layer')\n",
    "parser.add_argument(\n",
    "    \"--bidirectional\",\n",
    "    type=int,\n",
    "    default=0,\n",
    "    help=\"0 for disable, 1 for enable. encoder/decoder bidirectional.\")\n",
    "parser.add_argument(\n",
    "    '--input_dropout_p',\n",
    "    type=float,\n",
    "    default=0.2,\n",
    "    help='strength of dropout in the Language Model RNN')\n",
    "parser.add_argument(\n",
    "    '--rnn_type', type=str, default='gru', help='lstm or gru')\n",
    "\n",
    "parser.add_argument(\n",
    "    '--rnn_dropout_p',\n",
    "    type=float,\n",
    "    default=0.5,\n",
    "    help='strength of dropout in the Language Model RNN')\n",
    "\n",
    "parser.add_argument(\n",
    "    '--dim_word',\n",
    "    type=int,\n",
    "    default=300,  # 512\n",
    "    help='the encoding size of each token in the vocabulary, and the video.'\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--max_len\",\n",
    "    type=int,\n",
    "    default=350,\n",
    "    help='max length of captions(containing <sos>,<eos>)')\n",
    "\n",
    "opt, unknown = parser.parse_known_args()\n",
    "print(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f6331ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vinh/Research/Test/VSRN_New/GCN_lib/Rs_GCN.py:125: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
      "  nn.init.constant(self.W[1].weight, 0)\n",
      "/home/vinh/Research/Test/VSRN_New/GCN_lib/Rs_GCN.py:126: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
      "  nn.init.constant(self.W[1].bias, 0)\n",
      "/home/vinh/Virtual_Research/lib/python3.7/site-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n",
      "/home/vinh/Virtual_Research/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/vinh/Virtual_Research/lib/python3.7/site-packages/torch/optim/adam.py:48: UserWarning: optimizer contains a parameter group with duplicate parameters; in future, this will cause an error; see github.com/pytorch/pytorch/issues/40967 for more information\n",
      "  super(Adam, self).__init__(params, defaults)\n"
     ]
    }
   ],
   "source": [
    "vocab = pickle.load(open(os.path.join(\n",
    "    opt.vocab_path, '%s_vocab.pkl' % opt.data_name), 'rb'))\n",
    "opt.vocab_size = len(vocab)\n",
    "\n",
    "model = VSRN(opt)\n",
    "model.load_state_dict(torch.load('../runs/runX/model_best.pth.tar')['model'])\n",
    "model.val_start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c78079f",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('/media/vinh/Not_mix3/Research/ACMMM/cosmos_anns/train_data.json')\n",
    "train = []\n",
    "\n",
    "for line in f:\n",
    "    train.append(json.loads(line))\n",
    "\n",
    "f = open('../Data/caption_train.txt', 'r')\n",
    "captions = f.read()\n",
    "captions = captions.split('\\n')\n",
    "for i in range(len(captions)):\n",
    "    idx = captions[i].find('caption:') + 8\n",
    "    captions[i] = captions[i][idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eab7a92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.load(opt.data_path + 'Data_Npy/Train/train_' + str(1) + '.npy')\n",
    "rand_idx = np.arange(10000).tolist()\n",
    "random.shuffle(rand_idx)\n",
    "\n",
    "idx = 0\n",
    "idx_ = 10000\n",
    "cap1, cap2, label = take_cap(train, captions, idx_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d307ad62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.6635078825987876, -0.04161652168259025)\n"
     ]
    }
   ],
   "source": [
    "print(image_score(images, idx, idx_, cap1, cap2, train, model, vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fa7450f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-21 03:58:05.247959: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-05-21 03:58:07.076019: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2022-05-21 03:58:07.076166: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-21 03:58:07.076617: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 3060 computeCapability: 8.6\n",
      "coreClock: 1.837GHz coreCount: 28 deviceMemorySize: 11.77GiB deviceMemoryBandwidth: 335.32GiB/s\n",
      "2022-05-21 03:58:07.076640: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-05-21 03:58:07.079438: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2022-05-21 03:58:07.079495: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2022-05-21 03:58:07.080377: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2022-05-21 03:58:07.080619: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2022-05-21 03:58:07.081433: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11\n",
      "2022-05-21 03:58:07.082126: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2022-05-21 03:58:07.082271: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2022-05-21 03:58:07.082368: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-21 03:58:07.083014: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-21 03:58:07.083566: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2022-05-21 03:58:07.083888: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-21 03:58:07.084112: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-21 03:58:07.084503: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 3060 computeCapability: 8.6\n",
      "coreClock: 1.837GHz coreCount: 28 deviceMemorySize: 11.77GiB deviceMemoryBandwidth: 335.32GiB/s\n",
      "2022-05-21 03:58:07.084562: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-21 03:58:07.084973: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-21 03:58:07.085341: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2022-05-21 03:58:07.085372: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-05-21 03:58:10.863053: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-05-21 03:58:10.863083: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
      "2022-05-21 03:58:10.863090: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
      "2022-05-21 03:58:10.863275: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-21 03:58:10.863778: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-21 03:58:10.864234: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-21 03:58:10.864656: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8426 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:01:00.0, compute capability: 8.6)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "from transformers import pipeline\n",
    "from transformers import *\n",
    "import WK_Sbert.utils_sbert"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
